{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CPOXHysXKGLW"
   },
   "source": [
    "# TP RNN \n",
    "# Training language model (Many-to-Many) and generating sequences (One-to-Many)\n",
    "\n",
    "For any remark or suggestion, please feel free to contact me at:\n",
    "geoffroy.peeters@telecom-paristech.fr\n",
    "\n",
    "Last edit: 2019/01/15 geoffroy.peeters@telecom-paristech.fr\n",
    "\n",
    "### Objective:\n",
    "\n",
    "- We will train a network to learn a language model and then use it to generate new sequences.\n",
    "\n",
    "- Instead of training the language model on text-documents (as it is the case in most examples) we will train it to learn the language of the music of [Johann_Sebastian_Bach](https://en.wikipedia.org/wiki/Johann_Sebastian_Bach).\n",
    "For this, we will learn how J. S. Bach's \"Cello suite\" hav been composed.\n",
    "Here is an example of a \"Cello suite\" [Link](https://www.youtube.com/watch?v=mGQLXRTl3Z0).\n",
    "\n",
    "- Rather than analyzing the audio signal, we use a symbolic representation of the \"Cello suite\" through their [MIDI files](https://en.wikipedia.org/wiki/MIDI#MIDI_files).\n",
    "  - A MIDI file encodes in a file, the set of musical notes, their duration, and intensity which have to be played by each instrument to \"render\" a musical piece. The \"rendering\" is usually operated by a MIDI synthesizer (such as VLC, QuickTime).\n",
    "\n",
    "- We will first train a language model on the whole set of MIDI files of the \"Cello suites\". \n",
    "- We will then sample this language model to create a new MIDI file which will be a brand new \"Cello suite\" composed by the computer.\n",
    "\n",
    "### Questions:\n",
    "\n",
    "In the bottom part of this lab, you will have to answer a set of questions. Answers to those only necessitates a couple of sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RjlvVXvgbpbW"
   },
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IXocQU0HDntL"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pretty_midi\n",
    "from scipy.io import wavfile \n",
    "import IPython\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, LSTM, Flatten, Dropout, Activation\n",
    "from keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_gZx9igIOvtU"
   },
   "outputs": [],
   "source": [
    "n_x = 79\n",
    "max_T_x = 1000\n",
    "sequence_length = 20\n",
    "T_y_generated = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bgG1EmxKDhE5"
   },
   "source": [
    "## Collect data to create the language model\n",
    "\n",
    "We download the 36 MIDI files corresponding to the 36 \"Cello suites\" composed by J. S. Bach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "C9Tgx3ooDgSP",
    "outputId": "0f76ec00-6ead-46ca-bc3b-f6c370613151"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./cs2-3cou.mid', './cs4-6gig.mid', './cs5-4sar.mid', './cs2-4sar.mid', './cs5-6gig.mid', './cs5-2all.mid', './cs1-3cou.mid', './cs1-1pre.mid', './cs2-2all.mid', './cs6-2all.mid', './cs2-6gig.mid', './cs2-5men.mid', './cs5-1pre.mid', './cs4-1pre.mid', './cs3-1pre.mid', './cs5-5gav.mid', './cs3-2all.mid', './cs2-1pre.mid', './cs3-3cou.mid', './cs1-4sar.mid', './cs4-2all.mid', './cs6-4sar.mid', './cs1-6gig.mid', './cs4-5bou.mid', './cs3-5bou.mid', './cs4-3cou.mid', './cs1-2all.mid', './cs1-5men.mid', './cs6-3cou.mid', './cs5-3cou.mid', './cs4-4sar.mid', './cs6-1pre.mid', './cs3-4sar.mid', './cs6-5gav.mid', './cs6-6gig.mid', './cs3-6gig.mid']\n"
     ]
    }
   ],
   "source": [
    "DIR = './'\n",
    "import urllib.request\n",
    "midiFile_l = ['cs1-2all.mid', 'cs5-1pre.mid', 'cs4-1pre.mid', 'cs3-5bou.mid', 'cs1-4sar.mid', 'cs2-5men.mid', 'cs3-3cou.mid', 'cs2-3cou.mid', 'cs1-6gig.mid', 'cs6-4sar.mid', 'cs4-5bou.mid', 'cs4-3cou.mid', 'cs5-3cou.mid', 'cs6-5gav.mid', 'cs6-6gig.mid', 'cs6-2all.mid', 'cs2-1pre.mid', 'cs3-1pre.mid', 'cs3-6gig.mid', 'cs2-6gig.mid', 'cs2-4sar.mid', 'cs3-4sar.mid', 'cs1-5men.mid', 'cs1-3cou.mid', 'cs6-1pre.mid', 'cs2-2all.mid', 'cs3-2all.mid', 'cs1-1pre.mid', 'cs5-2all.mid', 'cs4-2all.mid', 'cs5-5gav.mid', 'cs4-6gig.mid', 'cs5-6gig.mid', 'cs5-4sar.mid', 'cs4-4sar.mid', 'cs6-3cou.mid']\n",
    "for midiFile in midiFile_l:\n",
    "  #if os.path.isfile(DIR + midiFile) is None:\n",
    "  urllib.request.urlretrieve (\"http://www.jsbach.net/midi/\" + midiFile, DIR + midiFile)\n",
    "nbExample = len(midiFile_l)\n",
    "\n",
    "midiFile_l = glob.glob(DIR + 'cs*.mid')\n",
    "print(midiFile_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HgCE_6urcVsj"
   },
   "source": [
    "## Read and convert all MIDI files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mDofyEKjcd4E"
   },
   "source": [
    "We read all MIDI files and convert their content to one-hot-encoding matrix X_ohe of dimensions (T_x, n_x) where n_x is the number of possible musical notes.\n",
    "The duration of the sequences T_x can vary from one sequence to the other.\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "EirVcbKxEe-3",
    "outputId": "1556b2bc-4a0c-4d87-a14d-153c1ef2c877"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "(580, 79)\n",
      "(966, 79)\n",
      "(216, 79)\n"
     ]
    }
   ],
   "source": [
    "# We truncate the duration of each example to the first T_x data\n",
    "\n",
    "X_list = []\n",
    "\n",
    "for midiFile in midiFile_l:\n",
    "    # read the MIDI file\n",
    "    midi_data = pretty_midi.PrettyMIDI(midiFile)\n",
    "    note_l = [note.pitch for note in midi_data.instruments[0].notes]\n",
    "    # convert to one-hot-encoding\n",
    "    T_x = len(note_l)\n",
    "    if T_x > max_T_x:\n",
    "      T_x = max_T_x\n",
    "    X_ohe = np.zeros((T_x, n_x))\n",
    "    for t in range(T_x): \n",
    "      X_ohe[t, note_l[t]-1] = 1\n",
    "    # add to the list  \n",
    "    X_list.append(X_ohe)\n",
    "    \n",
    "print(len(X_list))\n",
    "print(X_list[0].shape)\n",
    "print(X_list[1].shape)\n",
    "print(X_list[2].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nSf8RDL5cv7V"
   },
   "source": [
    "## Display the set of notes over time for a specific track "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "colab_type": "code",
    "id": "wesPFMZHcvKG",
    "outputId": "a6f087cd-d55b-4153-9a10-18b094623d3b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6IAAAFpCAYAAACGSJXZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABDCaIAAAAMJYgCAAAw1P8DKemk4RmozJ8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.imshow(X_list[2].T, aspect='auto')\n",
    "plt.set_cmap('gray_r')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PMHtioR_c5y3"
   },
   "source": [
    "## Data conversion for the training of language model\n",
    "\n",
    "For each example/sequence and each possible starting note in this example/sequence, we create two sequences\n",
    "- an input sequence: \n",
    "  - which contains a sub-sequence of length ```sequence_length```;  this sub-sequence range from the note $t$ to the note $t+sequence\\_length-1$\n",
    "- an output sequence:\n",
    "  - which contains the following note to be predicted, the one at position $t+sequence\\_length$\n",
    "\n",
    "The training is therefore performed by giving to the model a set of sequences as input and asking the network to predict each time the note that should come right after this sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 663
    },
    "colab_type": "code",
    "id": "EGzvp4RCC0XX",
    "outputId": "c406ba40-a983-4ec7-d8e4-ae0be8fa01a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (23745, 20, 79)\n",
      "y_train.shape: (23745, 79)\n"
     ]
    }
   ],
   "source": [
    "X_train_list = []\n",
    "y_train_list = []\n",
    "\n",
    "# CODE-RNN2-1\n",
    "# --- START CODE HERE\n",
    "for x in X_list:\n",
    "    for i in range(x.shape[0] - sequence_length - 1):\n",
    "        X_train_list.append(x[i:i+sequence_length,:])\n",
    "        y_train_list.append(x[i+sequence_length+1,:])\n",
    "# --- END CODE HERE\n",
    "\n",
    "X_train = np.asarray(X_train_list)\n",
    "y_train = np.asarray(y_train_list)\n",
    "\n",
    "print(\"X_train.shape:\", X_train.shape)\n",
    "print(\"y_train.shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HhNPrmvveuH3"
   },
   "source": [
    "# Training the language model\n",
    "\n",
    "The language model will be learned by training an RNN with input ```X_train``` and output ```Y_train```:  for each of the examples of sequences, we give to the network a sequence of notes of ```sequence_length``` duration, and ask the network to predict the following note of each sequence.\n",
    "\n",
    "The network will have the following structure\n",
    "- a layer of ```LSTM``` with $n_a$=256\n",
    "- a DropOut layer with rate 0.3 (the probability to \"drop-out\" one neuron is 0.3)\n",
    "- a second layer of ```LSTM``` with $n_a$=256\n",
    "- a DropOut layer with rate 0.3 (the probability to \"drop-out\" one neuron is 0.3)\n",
    "- a ```Dense``` layer with 256 units\n",
    "- a DropOut layer with rate 0.3 (the probability to \"drop-out\" one neuron is 0.3)\n",
    "- a ``Dense``` layer with a ```softmax``` activation which predict the probability of each of the $n_x$ notes as output\n",
    "\n",
    "Note that because we will stack two LSTM layers on top of each other (deep-RNN), we need to tell the first LSTM to output its hidden states at each time $t$. This is done by the option ```return_sequences=True``` that has to be given to the first LSTM.\n",
    "\n",
    "This is not the case of the second LSTM since we are only interrest in its final prediction (hence ```return_sequences=False``` which is the default behaviour)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "epWHM4p6D5n7",
    "outputId": "f817b39f-ad02-4f18-86c7-759bce369930"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 20, 79)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 20, 256)           344064    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 20, 256)           525312    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 20, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 79)                20303     \n",
      "=================================================================\n",
      "Total params: 1,480,783\n",
      "Trainable params: 1,480,783\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "K.clear_session()\n",
    "\n",
    "# CODE-RNN2-2\n",
    "# --- START CODE HERE\n",
    "from keras.models import Model\n",
    "\n",
    "input_ph = Input(shape=(sequence_length, n_x))\n",
    "m = LSTM(256, return_sequences=True)(input_ph)\n",
    "m = Dropout(0.3)(m)\n",
    "m = LSTM(256, return_sequences=True)(m)\n",
    "m = Dropout(0.3)(m)\n",
    "m = LSTM(256)(m)\n",
    "m = Dropout(0.3)(m)\n",
    "m = Dense(256)(m)\n",
    "m = Dropout(0.3)(m)\n",
    "m = Dense(n_x, activation='softmax')(m)\n",
    "model = Model(inputs = input_ph, outputs = m)\n",
    "# --- END CODE HERE\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "yhWTNfIbFDmf",
    "outputId": "9d794a5d-b8f6-4c53-cd4c-a0c94aa3c908"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23745/23745 [==============================] - 35s 1ms/step - loss: 2.9994 - acc: 0.1070\n",
      "Epoch 2/50\n",
      "23745/23745 [==============================] - 25s 1ms/step - loss: 2.7765 - acc: 0.1309\n",
      "Epoch 3/50\n",
      "23745/23745 [==============================] - 25s 1ms/step - loss: 2.7123 - acc: 0.1453\n",
      "Epoch 4/50\n",
      "23745/23745 [==============================] - 25s 1ms/step - loss: 2.6761 - acc: 0.1589\n",
      "Epoch 5/50\n",
      "23745/23745 [==============================] - 26s 1ms/step - loss: 2.6381 - acc: 0.1645\n",
      "Epoch 6/50\n",
      "23745/23745 [==============================] - 26s 1ms/step - loss: 2.5976 - acc: 0.1750\n",
      "Epoch 7/50\n",
      "23745/23745 [==============================] - 27s 1ms/step - loss: 2.5569 - acc: 0.1860\n",
      "Epoch 8/50\n",
      "23745/23745 [==============================] - 27s 1ms/step - loss: 2.5027 - acc: 0.2091\n",
      "Epoch 9/50\n",
      "23745/23745 [==============================] - 28s 1ms/step - loss: 2.4516 - acc: 0.2219\n",
      "Epoch 10/50\n",
      "23745/23745 [==============================] - 27s 1ms/step - loss: 2.3826 - acc: 0.2440\n",
      "Epoch 11/50\n",
      "23745/23745 [==============================] - 27s 1ms/step - loss: 2.2930 - acc: 0.2663\n",
      "Epoch 12/50\n",
      "23745/23745 [==============================] - 27s 1ms/step - loss: 2.2007 - acc: 0.2897\n",
      "Epoch 13/50\n",
      "23745/23745 [==============================] - 27s 1ms/step - loss: 2.0868 - acc: 0.3226\n",
      "Epoch 14/50\n",
      "23745/23745 [==============================] - 27s 1ms/step - loss: 1.9760 - acc: 0.3553\n",
      "Epoch 15/50\n",
      "23745/23745 [==============================] - 28s 1ms/step - loss: 1.8616 - acc: 0.3925\n",
      "Epoch 16/50\n",
      "23745/23745 [==============================] - 28s 1ms/step - loss: 1.7411 - acc: 0.4304\n",
      "Epoch 17/50\n",
      "23745/23745 [==============================] - 28s 1ms/step - loss: 1.6280 - acc: 0.4647\n",
      "Epoch 18/50\n",
      "23745/23745 [==============================] - 28s 1ms/step - loss: 1.5254 - acc: 0.4959\n",
      "Epoch 19/50\n",
      "23745/23745 [==============================] - 29s 1ms/step - loss: 1.4232 - acc: 0.5260\n",
      "Epoch 20/50\n",
      "23745/23745 [==============================] - 29s 1ms/step - loss: 1.3249 - acc: 0.5572\n",
      "Epoch 21/50\n",
      "23745/23745 [==============================] - 30s 1ms/step - loss: 1.2333 - acc: 0.5907\n",
      "Epoch 22/50\n",
      "23745/23745 [==============================] - 29s 1ms/step - loss: 1.1489 - acc: 0.6172\n",
      "Epoch 23/50\n",
      "23745/23745 [==============================] - 30s 1ms/step - loss: 1.0770 - acc: 0.6424\n",
      "Epoch 24/50\n",
      "23745/23745 [==============================] - 30s 1ms/step - loss: 0.9979 - acc: 0.6710\n",
      "Epoch 25/50\n",
      "23745/23745 [==============================] - 30s 1ms/step - loss: 0.9306 - acc: 0.6908\n",
      "Epoch 26/50\n",
      "23745/23745 [==============================] - 30s 1ms/step - loss: 0.8820 - acc: 0.7055\n",
      "Epoch 27/50\n",
      "23745/23745 [==============================] - 30s 1ms/step - loss: 0.8270 - acc: 0.7242\n",
      "Epoch 28/50\n",
      "23745/23745 [==============================] - 30s 1ms/step - loss: 0.7929 - acc: 0.7343\n",
      "Epoch 29/50\n",
      "23745/23745 [==============================] - 30s 1ms/step - loss: 0.7428 - acc: 0.7559\n",
      "Epoch 30/50\n",
      "23745/23745 [==============================] - 30s 1ms/step - loss: 0.7063 - acc: 0.7658\n",
      "Epoch 31/50\n",
      "23745/23745 [==============================] - 30s 1ms/step - loss: 0.6649 - acc: 0.7801\n",
      "Epoch 32/50\n",
      "23745/23745 [==============================] - 31s 1ms/step - loss: 0.6420 - acc: 0.7872\n",
      "Epoch 33/50\n",
      "23745/23745 [==============================] - 31s 1ms/step - loss: 0.5982 - acc: 0.8015\n",
      "Epoch 34/50\n",
      "23745/23745 [==============================] - 31s 1ms/step - loss: 0.5915 - acc: 0.8051\n",
      "Epoch 35/50\n",
      "23745/23745 [==============================] - 31s 1ms/step - loss: 0.5497 - acc: 0.8158\n",
      "Epoch 36/50\n",
      "23745/23745 [==============================] - 33s 1ms/step - loss: 0.5323 - acc: 0.8252\n",
      "Epoch 37/50\n",
      "23745/23745 [==============================] - 31s 1ms/step - loss: 0.5133 - acc: 0.8323\n",
      "Epoch 38/50\n",
      "23745/23745 [==============================] - 31s 1ms/step - loss: 0.4938 - acc: 0.8382\n",
      "Epoch 39/50\n",
      "23745/23745 [==============================] - 31s 1ms/step - loss: 0.4683 - acc: 0.8469\n",
      "Epoch 40/50\n",
      "23745/23745 [==============================] - 32s 1ms/step - loss: 0.4558 - acc: 0.8479\n",
      "Epoch 41/50\n",
      "23745/23745 [==============================] - 31s 1ms/step - loss: 0.4475 - acc: 0.8537\n",
      "Epoch 42/50\n",
      "23745/23745 [==============================] - 31s 1ms/step - loss: 0.4306 - acc: 0.8593\n",
      "Epoch 43/50\n",
      "23745/23745 [==============================] - 31s 1ms/step - loss: 0.4187 - acc: 0.8652\n",
      "Epoch 44/50\n",
      "23745/23745 [==============================] - 31s 1ms/step - loss: 0.4101 - acc: 0.8657\n",
      "Epoch 45/50\n",
      "23745/23745 [==============================] - 32s 1ms/step - loss: 0.3896 - acc: 0.8740\n",
      "Epoch 46/50\n",
      "23745/23745 [==============================] - 32s 1ms/step - loss: 0.3766 - acc: 0.8772\n",
      "Epoch 47/50\n",
      "23745/23745 [==============================] - 32s 1ms/step - loss: 0.3638 - acc: 0.8819\n",
      "Epoch 48/50\n",
      "23745/23745 [==============================] - 32s 1ms/step - loss: 0.3619 - acc: 0.8838\n",
      "Epoch 49/50\n",
      "23745/23745 [==============================] - 32s 1ms/step - loss: 0.3568 - acc: 0.8847\n",
      "Epoch 50/50\n",
      "23745/23745 [==============================] - 31s 1ms/step - loss: 0.3424 - acc: 0.8885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb7c22de4a8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile and fit the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xM6g1YR3gtcO"
   },
   "source": [
    "# Generating a new sequence from sampling the language model\n",
    "\n",
    "To generate a new sequence from the language model, we simply give it as input a random sequence of duration ```sequence_length```and ask the trained network to predict the output (using ```model.predict```). \n",
    "\n",
    "The output of the network is a vector of probability of dimension $n_x$ which represents the probability of each note to be the next note of the melody given as input.\n",
    "\n",
    "From this vector, we select the note which has the maximum probability.\n",
    "\n",
    "We then concatenate this new note (its one-hot-encoding representation) at the end of the input sequence.\n",
    "We finally remove the first element of the input sequence to keep its duration constant (```sequence_length```).\n",
    "\n",
    "Instead of providing a random sequence as input, we rather randomly select one sequence out of the 2880 sequences used for training.\n",
    "We denote it by ```pattern```.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "_YHXTohsFGCX",
    "outputId": "698cac08-9aa2-4dab-e986-2a5ba5e4f1ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3275\n",
      "(20, 79)\n",
      "(1, 20, 79)\n"
     ]
    }
   ],
   "source": [
    "# --- select a random starting pattern\n",
    "start = np.random.randint(0, len(X_train_list)-1)\n",
    "pattern = X_train_list[start]\n",
    "print(start)\n",
    "print(pattern.shape)\n",
    "print(np.expand_dims(pattern, 0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "f_ADCs7uFW8m"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51, 42, 44, 44, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 51, 59, 58, 59, 58, 56, 59, 56, 54, 54, 49, 52, 49, 46, 54, 56, 59, 61, 54, 52, 58, 54, 52, 54, 61, 61, 59, 56, 58, 56, 52, 52, 52, 52, 52, 46, 46, 58, 56, 58, 56, 54, 51, 49, 51, 51, 51, 48, 44, 44, 44, 39, 39, 52, 52, 51, 61, 61, 54, 59, 56, 59, 56, 47, 56, 56, 42, 56, 56, 59, 56, 49, 64, 59, 57, 49, 64, 56, 42, 58, 59, 58, 54, 64, 58, 61, 59, 59, 42, 61, 59, 42, 54, 53, 51, 61, 58, 51, 53, 56, 46, 58, 54, 49, 52, 49, 46, 52, 52, 47, 42, 42, 35, 50, 51, 42, 58, 59, 42, 54, 53, 50, 50, 47, 59, 59, 54, 53, 56, 42, 61, 59, 56, 54, 51, 53, 51, 51, 54, 59, 59, 54, 52, 49, 49, 46, 58, 58, 61, 58, 58, 54, 46, 52, 51, 52, 51, 47, 51, 54, 54, 51, 47, 54, 54, 57, 57, 54, 55, 54, 52, 52, 55, 55, 49, 47, 47]\n"
     ]
    }
   ],
   "source": [
    "note_l = []\n",
    "\n",
    "prediction_l = []\n",
    "# generate T_y_generated notes\n",
    "T_y_generated = 200\n",
    "l = pattern\n",
    "for note_index in range(T_y_generated):\n",
    "    # CODE-RNN2-3\n",
    "    # --- START CODE HERE\n",
    "    X = np.expand_dims(l, 0)\n",
    "    preds = model.predict(X)\n",
    "    pred = np.argmax(preds)\n",
    "    pred_ohe = np.zeros(n_x)\n",
    "    pred_ohe[pred] = 1\n",
    "    prediction_l.append(pred)\n",
    "    l = np.append(l, [pred_ohe], axis=0)\n",
    "    l = l[1:,:]\n",
    "    \n",
    "    # --- END CODE HERE\n",
    "    \n",
    "print(prediction_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "stQscvNOg0xd"
   },
   "source": [
    "### Display the generated sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "colab_type": "code",
    "id": "c9IOPPiuLuHE",
    "outputId": "0009943c-a0a2-485e-f2e6-0830dfe86f87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-d371c989f9c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprediction_l\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnote_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_cmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gray_r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1152x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(note_l)\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.imshow(np.asarray([prediction_l])[:,0,:].T, aspect='auto')\n",
    "plt.plot(note_l)\n",
    "plt.set_cmap('gray_r')\n",
    "plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZwM6osfDg5E0"
   },
   "source": [
    "### Create a MIDI file and an audio file which correspond to the generated sequence\n",
    "\n",
    "Once the new sequence has been generated (```note_l```) we transform it to a new MIDI file and perform (a very cheap) rendering of it in an audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "8cpTszOFID51"
   },
   "outputs": [],
   "source": [
    "#prediction_l = [54, 53, 49, 53, 57, 57, 54, 57, 54, 45, 49, 57, 57, 57, 57, 50, 50, 55, 57, 57, 59, 57, 54, 53, 51, 53, 54, 53, 53, 50, 50, 50, 47, 47, 53, 53, 56, 49, 49, 49, 50, 49, 49, 49, 54, 50, 50, 52, 54, 57, 57, 57, 54, 52, 52, 54, 54, 55, 52, 54, 54, 57, 57, 57, 57, 57, 54, 50, 54, 50, 54, 55, 52, 55, 52, 57, 57, 57, 50, 45, 38, 54, 50, 50, 50, 47, 50, 45, 47, 50, 53, 49, 49, 49, 47, 45, 47, 50, 47, 47, 44, 47, 47, 49, 52, 49, 49, 52, 52, 49, 46, 52, 52, 46, 52, 52, 46, 52, 52, 35, 47, 35, 42, 47, 47, 42, 51, 49, 49, 47, 51, 35, 42, 51, 51, 47, 47, 51, 59, 59, 54, 52, 51, 42, 40, 44, 44, 51, 51, 51, 54, 39, 40, 37, 57, 51, 54, 52, 57, 54, 52, 47, 54, 56, 47, 54, 57, 56, 54, 56, 54, 56, 49, 52, 49, 46, 46, 42, 59, 59, 54, 52, 51, 54, 51, 59, 59, 54, 54, 52, 51, 59, 59, 42, 58, 59, 42, 59, 59, 54]\n",
    "new_midi_data = pretty_midi.PrettyMIDI()\n",
    "cello_program = pretty_midi.instrument_name_to_program('Cello')\n",
    "cello = pretty_midi.Instrument(program=cello_program)\n",
    "time = 0\n",
    "step = 0.15\n",
    "note_l = prediction_l\n",
    "for note_number in note_l:\n",
    "    myNote = pretty_midi.Note(velocity=100, pitch=note_number, start=time, end=time+step)\n",
    "    cello.notes.append(myNote)\n",
    "    time += step\n",
    "new_midi_data.instruments.append(cello)\n",
    "new_midi_data.write(\"out_new.mid\")\n",
    "midi_data.write(\"real_bach.mid\")\n",
    "#%matplotlib inline\n",
    "\n",
    "#audio_data = new_midi_data.synthesize()\n",
    "#IPython.display.Audio(audio_data, rate=44100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sgjoIxEqL7bx"
   },
   "source": [
    "### Question 1) Que se passe-t'il si on remplace la cellule LSTM par une cellule RNNsimple ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We lose the netwoks ability to decide what to remember, and in this case lose context when predicting notes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2) Que se passe-t'il si l'on raccourci la longueur des séquences utilisées pour l'entrainement ? Comment palier à cet effet ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J'imagine que cela devient plus facile pour le modèle de faire de l'overfitting. Pourquoi pas rajouter du dropout ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3) Comment pourrait-on rendre le système ```polyphonique``` (plusieurs notes jouées simultanément par le même instrument) ? pour l'entrainement ? pour la génération ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequencing many-to-one models\n",
    "\n",
    "In the following model, we chain many to one models to predict one note at a time. If we need to predict $n$ notes, we define $n$ models. The first one finding the first note based on an input sequence, the second one a second note based on the input sequence and the first predicted note and so on. We define the model formally bellow.\n",
    "\n",
    "Let $\\mathcal{N} = \\{1,…,\\Delta\\}\\cup\\{-1\\}, \\Delta \\in \\mathbb{N}, \\Delta > 1$ be the set of notes, $-1$ denoting the absence of note.\n",
    "Let $N \\in \\mathcal{N}^{p_1\\times p_2}$ be a sequence of $p_2$-uplets of notes of length $p_1$.\n",
    "Let the training set $\\mathcal{T} \\subset \\mathcal{N}^{n\\times p_1 \\times p_2}$ be a list of length $n$ of $p_1$ sequences of $p_2$-uplets of notes.\n",
    "\n",
    "Let us define a transform $f^{(1)}$ that converts our trainging data to interpretable form. We use a function $OHE: \\mathcal{N} \\longrightarrow \\mathcal{D}$, $\\mathcal{D}$ being the set of one hot encoded notes, $\\mathcal{D} = \\{d: d\\in\\{0, 1\\}^{\\Delta}, \\sum_{i=1}^\\Delta d_i = 1\\}$:\n",
    "\n",
    "$$\n",
    "f^{(1)}: \\mathcal{N}^{n\\times p_1\\times p_2} \\longrightarrow \\mathcal{D}^{n\\times p_1\\times p_2} \\subset \\{0,1\\}^{n\\times p_1\\times \\Delta p_2}\n",
    "$$\n",
    "\n",
    "For $T \\in \\mathcal{T}$, we define:\n",
    "\n",
    "$$\n",
    "f^{(1)}(T)_{mij} = OHE(T_{mi\\alpha})_{\\beta}\n",
    "\\begin{cases}\n",
    "    \\alpha = floor\\left(\\frac{j}{\\Delta}\\right) + 1 \\textrm{ if } j\\bmod\\Delta \\neq 0 \\textrm{ else } \\frac{j}{\\Delta} \\\\\n",
    "    \\beta = j\\bmod\\Delta \\textrm{ if } j\\bmod\\Delta \\neq 0 \\textrm{ else } \\Delta\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Our training tensor is thus: $X = f^{(1)}(T) \\in \\mathcal{D}^{n\\times p_1\\times p_2}$ for $T \\in \\mathcal{T}$.\n",
    "\n",
    "We want to predict a $p_2$-uplet of notes given an ordered $p_1$-uplet of $p_2$-uplet of notes. Our strategy is to train $p_2$ models that each predict a note. These models, $m_i, i=1,…,p_2$, feed into each other and are defined as follows:\n",
    "\n",
    "$$\n",
    "m_i: \\mathcal{D}^{p_1\\times (p_2+i-1)} \\longrightarrow \\mathcal{D}\n",
    "$$\n",
    "\n",
    "For an input sequence of songs $X \\in \\mathcal{N}^{n\\times p_1\\times p_2}$, we want to predict the next notes for each sequence $y \\in \\mathcal{N}^{n\\times p_2}$:\n",
    "\n",
    "$$\n",
    "y^{pred}_{si} = OHE^{-1}\\left[ m_i\\left(\\tilde{X}^{(i)}_s\\right) \\right] \\in \\mathcal{N} \\\\\n",
    "s = 1,…,n \\\\\n",
    "i = 1,…,p_2\n",
    "$$\n",
    "\n",
    "Where $\\tilde{X}^{(i)}_{s} \\in \\mathcal{D}^{p_1\\times p_2} \\subset \\{0,1\\}^{p_1\\times \\Delta p_2}$:\n",
    "\n",
    "$$\n",
    "\\tilde{X}^{(i)}_{skl} = \n",
    "\\begin{cases}\n",
    "    f^{(1)}(X)_{skl} \\textrm{ if } k\\leq p_1, j\\leq \\Delta p_2 \\\\\n",
    "    m_\\alpha\\left[\\tilde{X}^{(\\alpha)}_s\\right]_{k\\beta} \\textrm{ otherwise }\n",
    "\\end{cases} \\\\\n",
    "i = 1,…,p_2 \\\\\n",
    "s = 1,…,n \\\\\n",
    "k = 1,…,p_1 \\\\\n",
    "l = 1,…,\\Delta(p_2 + i - 1) \\\\\n",
    "\\alpha = (l-\\Delta p_2)\\bmod\\Delta \\textrm{ if } (l-\\Delta p_2)\\bmod\\Delta \\neq 0 \\textrm{ else } \\frac{l-\\Delta p_2}{\\Delta} \\\\\n",
    "\\beta = l\\bmod\\Delta \\textrm{ if } l\\bmod \\Delta \\neq 0 \\textrm{ else } \\Delta\n",
    "$$\n",
    "\n",
    "Training our model is done as such: we start with a training set $T \\in \\mathcal{T} \\subset \\mathcal{N}^{n\\times p_1 \\times p_2}$ as defined earlier. We then have $p_2$ models to train, our $p_2$ train matrices $X^{(i)}, i = 1,…,p_2$ are obtained as follows:\n",
    "\n",
    "$$\n",
    "X^{(i)}_{skl} = \n",
    "\\begin{cases}\n",
    "    f^{(1)}(T)_{skl} \\textrm{ if } l \\leq \\Delta p_2 \\\\\n",
    "    f^{(1)}(T)_{(s+1)1(l-\\Delta p_2)} \\textrm{ otherwise }\n",
    "\\end{cases} \\\\\n",
    "$$\n",
    "\n",
    "Our associated label matrices for each $i$ models, $Y^{(i)} \\in \\mathcal{D}^{n\\times p_2}$:\n",
    "\n",
    "$$\n",
    "Y^{(i)}_{sl} = f^{(1)}(T)_{(s+1)1l} \\\\\n",
    "$$\n",
    "\n",
    "With $s = 1,…,n$ and $l = 1,…,p_2$.\n",
    "\n",
    "Finally, our $p_2$ LSTM networks are parametered by $\\theta_i, i = 1,…,p_2$, the best of which are found by solving the following minimization problem:\n",
    "\n",
    "$$\n",
    "\\hat{\\theta}_i \\in \\underset{\\theta_i}{\\mathrm{argmin}} \\mathcal{L}\\{m_i(X^{(i)}),Y^{(i)}\\}\n",
    "$$\n",
    "\n",
    "Where $\\mathcal{L}$ is the categorical cross entropy.\n",
    "\n",
    "Simply put, this gives us:\n",
    "\n",
    "$$\n",
    "y^{pred}_1 = \\underset{\\tilde{n}}{\\mathrm{argmax}} \\mathbb{P}(n_1=\\tilde{n}, \\tilde{n}\\in \\mathcal{N} | X^{(1)}) \\\\\n",
    "y^{pred}_2 = \\underset{\\tilde{n}}{\\mathrm{argmax}} \\mathbb{P}(n_1=\\tilde{n}, \\tilde{n}\\in \\mathcal{N} | X^{(1)}, y^{pred}_1) \\\\\n",
    "… \\\\\n",
    "y^{pred}_{p_2} = \\underset{\\tilde{n}}{\\mathrm{argmax}} \\mathbb{P}(n_1=\\tilde{n}, \\tilde{n}\\in \\mathcal{N} | X^{(1)}, y^{pred}_1, …, y^{pred}_{p_2-1})\n",
    "$$\n",
    "\n",
    "This model seems robust in the way that it can predict an arbitrary number of variables. We could include multiple instruments, note durations, or restrict notes to particular sets of chords and scales amongst other features.\n",
    "\n",
    "## Many-to-many\n",
    "\n",
    "We could also use a single many to many LSTM model $m$ and consider the output note vector at each timested to be played simultaneously. In the previous notation, we use training matrices $X^{(1)}$ only but redefine our labels as $Y \\in \\mathcal{N}^{n\\times p_2}$.\n",
    "\n",
    "Our minimization problem becomes:\n",
    "\n",
    "$$\n",
    "\\hat{\\theta} \\in \\underset{\\theta}{\\mathrm{argmin}} \\mathcal{L}\\{m(X^{(1)}),Y\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4) Nous avons utilisé une procédure simplifiée pour entrainer le modèle de language musical, en transformant l'apprentissage en un problème Many-To-one. Expliquez ? Comment entraine-t'on habituellement un modèle de language avec un RNN ? Quel en serait l'avantage ?\n",
    "\n",
    "On a entrainé notre modèle pour ne prédire qu'une seule à la fois. Un modèle many to many nous permetterai de pouvoir prédire des séquences et donc à notre modèle d'avoir plus de \"vision\" dans ses prédictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Réponse ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TP_RNN_Bach_simple.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
